{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Data preprocessing\n",
    "\n",
    "The following notebook is used to load the raw data, i.e., the results of wind farm control optimizations, preprocessing and finally convert it to PyTorch tensors. The raw data was not shared as was quite memory-intensive and not the main focus of this work. The preprocessed data can be downloaded at this [link](https://dtudk-my.sharepoint.com/:u:/g/personal/nicit_dtu_dk/EX96_QZYCQZMhQgLV_bEnl0BgosY2sJLT1s48-sCzHR6Cw?e=jhTNmx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'notebooks/'\n",
      "/home/nicit/deep_learning_course_wfco/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd notebooks/     # go to the notebooks directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw dataset of WFC optimizations and check the shapes of the keys. The data was collected in 100 recorders, each containing 960 different layouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders: 100%|██████████| 100/100 [00:21<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/nicit/nordsoen/nordsoen-i-wflo/results/DL/recorders_SLSQP_simple/\"\n",
    "\n",
    "recorders = {}\n",
    "n_layouts = 1000\n",
    "\n",
    "# for each of the random states, load the recorder\n",
    "for random_state in trange(int(n_layouts/10), desc=\"Loading recorders\"):\n",
    "    # load pickle\n",
    "    with open(folder_path + f\"recorder_{random_state}.pkl\", \"rb\") as f:\n",
    "                recorders[random_state] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_rot shape:  (31, 5)\n",
      "y_rot shape:  (31, 5)\n",
      "yaw shape:  (5, 31, 9)\n",
      "ws_eff shape:  (5, 31, 9)\n",
      "ti_eff shape:  (5, 31, 9)\n",
      "ws shape:  (9,)\n",
      "aep shape:  (31, 9)\n",
      "aep_opt shape:  (31, 9)\n",
      "yaw shape:  (5, 31, 9)\n"
     ]
    }
   ],
   "source": [
    "# Print all shapes\n",
    "print('x_rot shape: ', recorders[5][6000]['x_rot'].shape)    # x coordinates rotated to the wind direction of 270°\n",
    "print('y_rot shape: ', recorders[5][6000]['y_rot'].shape)    # y coordinates rotated to the wind direction of 270°\n",
    "print('ws_eff shape: ', recorders[5][6000]['ws_eff'].shape)  # effective wind speed at each turbine\n",
    "print('ti_eff shape: ', recorders[5][6000]['ti_eff'].shape)  # effective turbulence intensity at each turbine\n",
    "print('ws shape: ', recorders[5][6000]['ws'].shape)          # freestream wind speed\n",
    "print('yaw shape: ', recorders[5][6000]['yaw'].shape)        # yaw angles optimized with SLSQP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each optimization we need to extract the downwind and crosswind distance of the 5 downstream turbines, the effective wind speed, effective TI, and freestream wind speed. Then, as described in the report, we add 5 wake indexes to indicate whetherer a turbine is considered to be in the wake of the upstream turbine or not.\n",
    "\n",
    "We also need to adjust the shape of the dataset so that we have one yaw angle (one wind turbine) for each row of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders: 100%|██████████| 100/100 [00:07<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes: X = torch.Size([133920000, 18]), Y = torch.Size([133920000])\n",
      "Dataset saved to 5wt_dataset_1000_slsqp_simple_complete.pt\n"
     ]
    }
   ],
   "source": [
    "n_layouts = 1000\n",
    "rotor_diameter = 284.0              # rotor diameter of the wind turbine used for the optimizations\n",
    "nearest_idx = [0, 1, 2, 3, 4]       # indices of the nearest turbines to consider (5 nearest turbines)\n",
    "\n",
    "\n",
    "# --- Step 1: Load and aggregate all layouts ---\n",
    "all_x_rot = []\n",
    "all_y_rot = []\n",
    "all_ws_eff = []\n",
    "all_ti_eff = []\n",
    "all_yaw = []\n",
    "all_ws = []\n",
    "\n",
    "for random_state in tqdm(range(int(n_layouts / 10)), desc=\"Loading recorders\"):\n",
    "\n",
    "    file_path = folder_path + f\"recorder_{random_state}.pkl\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        recorder = pickle.load(f)\n",
    "    for result in recorder.values():\n",
    "        all_x_rot.append(result[\"x_rot\"])       # (n_dir, n_turbines)\n",
    "        all_y_rot.append(result[\"y_rot\"])\n",
    "        all_ws_eff.append(result[\"ws_eff\"])     # (n_turbines, n_dir, n_ws)\n",
    "        all_ti_eff.append(result[\"ti_eff\"])\n",
    "        all_yaw.append(result[\"yaw\"])\n",
    "        all_ws.append(result[\"ws\"])             # (n_ws,)\n",
    "\n",
    "# Stack everything\n",
    "x_rot_all = np.stack(all_x_rot)       # (n_layouts, n_dir, n_turbines)\n",
    "y_rot_all = np.stack(all_y_rot)\n",
    "ws_eff_all = np.stack(all_ws_eff)     # (n_layouts, n_turbines, n_dir, n_ws)\n",
    "ti_eff_all = np.stack(all_ti_eff)\n",
    "yaw_all = np.stack(all_yaw)\n",
    "ws_all = np.stack(all_ws)             # (n_layouts, n_ws)\n",
    "\n",
    "n_layouts_total, n_dir, n_turbines = x_rot_all.shape\n",
    "n_ws = ws_all.shape[1]\n",
    "n_cases = n_layouts_total * n_dir * n_ws\n",
    "\n",
    "# print(f\"Aggregated shapes: x_rot_all={x_rot_all.shape}, ws_eff_all={ws_eff_all.shape}\")\n",
    "\n",
    "# --- Step 2: Compute dx, dy for all layouts and directions ---\n",
    "# Flatten layouts and directions for _process_layout\n",
    "x_rot_flat = x_rot_all.reshape(-1, n_turbines)  # (n_layouts * n_dir, n_turbines)\n",
    "y_rot_flat = y_rot_all.reshape(-1, n_turbines)\n",
    "\n",
    "dx_all, dy_all = utils._process_layout(\n",
    "    turbine_x=x_rot_flat,\n",
    "    turbine_y=y_rot_flat,\n",
    "    rotor_diameter=rotor_diameter,\n",
    "    nearest_idx=nearest_idx,\n",
    "    normalize=True,\n",
    "    spread=.1\n",
    ")  # shape: (len(nearest_idx), n_turbines, n_layouts * n_dir)\n",
    "\n",
    "# Repeat across wind speeds\n",
    "dx_flat = np.repeat(dx_all, n_ws, axis=2).reshape(len(nearest_idx), n_turbines, n_cases)\n",
    "dy_flat = np.repeat(dy_all, n_ws, axis=2).reshape(len(nearest_idx), n_turbines, n_cases)\n",
    "\n",
    "# --- Step 3: Flatten dynamic inputs ---\n",
    "ws_eff_flat = ws_eff_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "ws_eff_flat = ws_eff_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "ti_eff_flat = ti_eff_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "ti_eff_flat = ti_eff_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "yaw_flat = yaw_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "yaw_flat = yaw_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "# Repeat ws for all layouts and directions\n",
    "# ws_rep = np.tile(ws_all.reshape(-1), n_dir)  # (n_cases,)\n",
    "ws_rep = np.tile(ws_all.reshape(n_layouts_total, n_ws), (1, n_dir)).reshape(n_cases)\n",
    "\n",
    "# --- Step 4: Build feature matrix in one shot ---\n",
    "dx_part = dx_flat.transpose(1, 2, 0)  # (n_turbines, n_cases, 5)\n",
    "dy_part = dy_flat.transpose(1, 2, 0)\n",
    "\n",
    "# modify this so that it is -1 when it is not waked (or waked), instaed of zero!\n",
    "waked_part = np.where(dx_part != np.inf, 1.0, -1.0)\n",
    "\n",
    "# Replace inf with nan for dx/dy\n",
    "dx_part[dx_part == np.inf] = np.nan\n",
    "\n",
    "# when there is nan in the corresponding dx, set dy to nan as well\n",
    "dy_part[dy_part == np.inf] = np.nan\n",
    "\n",
    "# Ensure dy is NaN wherever dx is NaN\n",
    "dy_part[np.isnan(dx_part)] = np.nan\n",
    "\n",
    "# adjust so that whenever the ws_eff is >= 12, the yaw should be zero\n",
    "yaw_flat = np.where((ws_eff_flat >= 10.5) \n",
    "                    # & (np.abs(yaw_flat) == 25.0)\n",
    "                    , 0.0, yaw_flat)\n",
    "\n",
    "# same whenever ws_eff is < 4\n",
    "yaw_flat = np.where(ws_eff_flat < 4.0, 0.0, yaw_flat)\n",
    "\n",
    "# round the yaw to the nearest float with 1 decimal place\n",
    "yaw_flat = np.round(yaw_flat, 1)\n",
    "\n",
    "# Static features: dx, dy, waked flags\n",
    "static_features = np.concatenate([dx_part, dy_part, \n",
    "                                waked_part\n",
    "                                  ], axis=2)  # (n_turbines, n_cases, 15)\n",
    "\n",
    "# merge ws and ws_eff into one feature (the difference)\n",
    "dynamic_features = np.stack([\n",
    "    ws_eff_flat,\n",
    "    ti_eff_flat,\n",
    "    np.tile(ws_rep, (n_turbines, 1))\n",
    "], axis=2)\n",
    "\n",
    "# Combine all features\n",
    "X = np.concatenate([static_features, dynamic_features], axis=2)  # (n_turbines, n_cases, 18)\n",
    "X = X.reshape(-1, X.shape[2])  # (n_turbines * n_cases, 18)\n",
    "Y = yaw_flat.reshape(-1)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "Y_torch = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "print(f\"Final dataset shapes: X = {X_torch.shape}, Y = {Y_torch.shape}\")\n",
    "\n",
    "# Save dataset\n",
    "torch.save((X_torch, Y_torch), f\"../data/5wt_dataset_{n_layouts}_slsqp_simple_complete.pt\")\n",
    "print(f\"Dataset saved to 5wt_dataset_{n_layouts}_slsqp_simple_complete.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wflo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
