{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nicit/deep_learning_course_wfco/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/nicit/nordsoen/nordsoen-i-wflo/results/DL/recorders/\"\n",
    "\n",
    "recorders = {}\n",
    "n_layouts = 100\n",
    "# load pickle\n",
    "for random_state in trange(int(n_layouts/100), desc=\"Loading recorders\"):\n",
    "    with open(folder_path + f\"recorder_{random_state}.pkl\", \"rb\") as f:\n",
    "        recorders[random_state] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['yaw', 'x', 'y', 'x_rot', 'y_rot', 'd_x', 'd_y', 'sort_idx', 'ws_eff', 'ti_eff', 'ws', 'aep', 'aep_opt'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorders[0][1000].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_rot shape:  (360, 46)\n",
      "y_rot shape:  (360, 46)\n",
      "yaw shape:  (46, 360, 11)\n",
      "ws_eff shape:  (46, 360, 11)\n",
      "ti_eff shape:  (46, 360, 11)\n",
      "ws shape:  (11,)\n",
      "aep shape:  [[0.00437259 0.00587007 0.03076611 ... 0.13747569 0.01684455 0.02444979]\n",
      " [0.00434477 0.00583548 0.03062883 ... 0.14218515 0.01743774 0.02528761]\n",
      " [0.00431171 0.00579388 0.03045422 ... 0.14669767 0.01801246 0.02614194]\n",
      " ...\n",
      " [0.00448134 0.00601999 0.0316177  ... 0.17683724 0.02217008 0.03242694]\n",
      " [0.00445364 0.00598145 0.03139479 ... 0.16316903 0.02030696 0.02962891]\n",
      " [0.00441877 0.00593384 0.03112336 ... 0.15002525 0.01852943 0.02696669]]\n",
      "aep_opt shape:  (360, 11)\n",
      "yaw shape:  (46, 360, 11)\n"
     ]
    }
   ],
   "source": [
    "print('x_rot shape: ', recorders[0][1000]['x_rot'].shape)\n",
    "print('y_rot shape: ', recorders[0][1000]['y_rot'].shape)\n",
    "print('yaw shape: ', recorders[0][1000]['yaw'].shape)\n",
    "print('ws_eff shape: ', recorders[0][1000]['ws_eff'].shape)\n",
    "print('ti_eff shape: ', recorders[0][1000]['ti_eff'].shape)\n",
    "print('ws shape: ', recorders[0][1000]['ws'].shape)\n",
    "print('aep shape: ', recorders[0][1000]['aep'])\n",
    "print('aep_opt shape: ', recorders[0][1000]['aep_opt'].shape)\n",
    "print('yaw shape: ', recorders[0][1000]['yaw'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading recorders: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes: X = torch.Size([18216000, 18]), Y = torch.Size([18216000])\n",
      "Dataset saved to 5wt_dataset_100.pt\n"
     ]
    }
   ],
   "source": [
    "n_layouts = 100\n",
    "rotor_diameter = 284.0  # adjust to your turbine specs\n",
    "nearest_idx = [0, 1, 2, 3, 4]\n",
    "\n",
    "\n",
    "# --- Step 1: Load and aggregate all layouts ---\n",
    "all_x_rot = []\n",
    "all_y_rot = []\n",
    "all_ws_eff = []\n",
    "all_ti_eff = []\n",
    "all_yaw = []\n",
    "all_ws = []\n",
    "\n",
    "for random_state in tqdm(range(int(n_layouts / 100)), desc=\"Loading recorders\"):\n",
    "    file_path = folder_path + f\"recorder_{random_state}.pkl\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        recorder = pickle.load(f)\n",
    "    for result in recorder.values():\n",
    "        all_x_rot.append(result[\"x_rot\"])       # (n_dir, n_turbines)\n",
    "        all_y_rot.append(result[\"y_rot\"])\n",
    "        all_ws_eff.append(result[\"ws_eff\"])     # (n_turbines, n_dir, n_ws)\n",
    "        all_ti_eff.append(result[\"ti_eff\"])\n",
    "        all_yaw.append(result[\"yaw\"])\n",
    "        all_ws.append(result[\"ws\"])             # (n_ws,)\n",
    "\n",
    "# Stack everything\n",
    "x_rot_all = np.stack(all_x_rot)       # (n_layouts, n_dir, n_turbines)\n",
    "y_rot_all = np.stack(all_y_rot)\n",
    "ws_eff_all = np.stack(all_ws_eff)     # (n_layouts, n_turbines, n_dir, n_ws)\n",
    "ti_eff_all = np.stack(all_ti_eff)\n",
    "yaw_all = np.stack(all_yaw)\n",
    "ws_all = np.stack(all_ws)             # (n_layouts, n_ws)\n",
    "\n",
    "n_layouts_total, n_dir, n_turbines = x_rot_all.shape\n",
    "n_ws = ws_all.shape[1]\n",
    "n_cases = n_layouts_total * n_dir * n_ws\n",
    "\n",
    "# print(f\"Aggregated shapes: x_rot_all={x_rot_all.shape}, ws_eff_all={ws_eff_all.shape}\")\n",
    "\n",
    "# --- Step 2: Compute dx, dy for all layouts and directions ---\n",
    "# Flatten layouts and directions for _process_layout\n",
    "x_rot_flat = x_rot_all.reshape(-1, n_turbines)  # (n_layouts * n_dir, n_turbines)\n",
    "y_rot_flat = y_rot_all.reshape(-1, n_turbines)\n",
    "\n",
    "dx_all, dy_all = utils._process_layout(\n",
    "    turbine_x=x_rot_flat,\n",
    "    turbine_y=y_rot_flat,\n",
    "    rotor_diameter=rotor_diameter,\n",
    "    nearest_idx=nearest_idx,\n",
    "    normalize=True,\n",
    "    spread=.1\n",
    ")  # shape: (len(nearest_idx), n_turbines, n_layouts * n_dir)\n",
    "\n",
    "# Repeat across wind speeds\n",
    "dx_flat = np.repeat(dx_all, n_ws, axis=2).reshape(len(nearest_idx), n_turbines, n_cases)\n",
    "dy_flat = np.repeat(dy_all, n_ws, axis=2).reshape(len(nearest_idx), n_turbines, n_cases)\n",
    "\n",
    "# --- Step 3: Flatten dynamic inputs ---\n",
    "ws_eff_flat = ws_eff_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "ws_eff_flat = ws_eff_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "ti_eff_flat = ti_eff_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "ti_eff_flat = ti_eff_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "yaw_flat = yaw_all.reshape(n_layouts_total, n_turbines, n_dir * n_ws)\n",
    "yaw_flat = yaw_flat.transpose(1, 0, 2).reshape(n_turbines, n_cases)\n",
    "\n",
    "# Repeat ws for all layouts and directions\n",
    "# ws_rep = np.tile(ws_all.reshape(-1), n_dir)  # (n_cases,)\n",
    "ws_rep = np.tile(ws_all.reshape(n_layouts_total, n_ws), (1, n_dir)).reshape(n_cases)\n",
    "\n",
    "# --- Step 4: Build feature matrix in one shot ---\n",
    "dx_part = dx_flat.transpose(1, 2, 0)  # (n_turbines, n_cases, 5)\n",
    "dy_part = dy_flat.transpose(1, 2, 0)\n",
    "\n",
    "# modify this so that it is -1 when it is not waked (or waked), instaed of zero!\n",
    "waked_part = np.where(dx_part != np.inf, 1.0, -1.0)\n",
    "\n",
    "# Replace inf with nan for dx/dy\n",
    "dx_part[dx_part == np.inf] = np.nan\n",
    "\n",
    "# when there is nan in the corresponding dx, set dy to nan as well\n",
    "dy_part[dy_part == np.inf] = np.nan\n",
    "\n",
    "# Ensure dy is NaN wherever dx is NaN\n",
    "dy_part[np.isnan(dx_part)] = np.nan\n",
    "\n",
    "# adjust so that whenever the ws_eff is >= 12, the yaw should be zero\n",
    "yaw_flat = np.where(ws_eff_flat >= 12.0, 0.0, yaw_flat)\n",
    "\n",
    "# same whenever ws_eff is < 4\n",
    "yaw_flat = np.where(ws_eff_flat < 4.0, 0.0, yaw_flat)\n",
    "\n",
    "# Static features: dx, dy, waked flags\n",
    "static_features = np.concatenate([dx_part, dy_part, \n",
    "                                waked_part\n",
    "                                  ], axis=2)  # (n_turbines, n_cases, 15)\n",
    "\n",
    "# merge ws and ws_eff into one feature (the difference)\n",
    "dynamic_features = np.stack([\n",
    "    ws_eff_flat,\n",
    "    ti_eff_flat,\n",
    "    np.tile(ws_rep, (n_turbines, 1))\n",
    "], axis=2)\n",
    "\n",
    "# Combine all features\n",
    "X = np.concatenate([static_features, dynamic_features], axis=2)  # (n_turbines, n_cases, 18)\n",
    "X = X.reshape(-1, X.shape[2])  # (n_turbines * n_cases, 18)\n",
    "Y = yaw_flat.reshape(-1)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "Y_torch = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "print(f\"Final dataset shapes: X = {X_torch.shape}, Y = {Y_torch.shape}\")\n",
    "\n",
    "# Save dataset\n",
    "torch.save((X_torch, Y_torch), f\"../data/5wt_dataset_{n_layouts}.pt\")\n",
    "print(f\"Dataset saved to 5wt_dataset_{n_layouts}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in X:  125842046\n",
      "Shape of X:  torch.Size([18216000, 18])\n",
      "Number of total data points in X 327888000\n",
      "Percentage of NaNs in X 38.38 %\n"
     ]
    }
   ],
   "source": [
    "# check nans in X\n",
    "print('Number of NaNs in X: ', torch.isnan(X_torch).sum().item())\n",
    "print('Shape of X: ', X_torch.shape)\n",
    "print(\"Number of total data points in X\", X_torch.shape[0]*X_torch.shape[1])\n",
    "print(\"Percentage of NaNs in X\", round(torch.isnan(X_torch).sum().item()/(X_torch.shape[0]*X_torch.shape[1])*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.3937,     nan,     nan,     nan,     nan, -1.7280,     nan,     nan,\n",
      "            nan,     nan,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  3.0525,\n",
      "         0.0600,  3.0525])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# i 10 is the weird stuff\n",
    "i = 15840\n",
    "print(X_torch[i])\n",
    "print(Y_torch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with wind speed < 3.2 m/s: 314640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(15840)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index where last value is < 3.2\n",
    "indices = (X_torch[:, -1] < 3.2).nonzero(as_tuple=True)[0]\n",
    "print(f\"Number of samples with wind speed < 3.2 m/s: {len(indices)}\")\n",
    "indices[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wflo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
